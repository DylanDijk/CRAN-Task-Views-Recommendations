library(igraph)
library(bc3net)
library(cranly)
library(RWsearch)
library(lubridate)


#### Objects needed to run generated by previous script ####
# tvdb
# CRAN_data
# CRAN_cranly_data
# all_CRAN_pks


#### Objects Outputted ####
# feature_matrix_titles_descriptions_packages_cosine



########## Data #########################

#### pins code ####
#library(pins)
# board = board_folder(path = "Pins_board/")
# 
# tvdb             = board %>% pin_read("tvdb")
# CRAN_data        = board %>% pin_read("CRAN_data")
# CRAN_cranly_data = board %>% pin_read("CRAN_cranly_data")
# all_CRAN_pks     = board %>% pin_read("all_CRAN_pks")

#########


# For some packages on CRAN the authors have not been listed in the standard way.
# Which causes these packages to have zero authors listed.
# The work around I have used is by setting the maintainer as the author

# Identifying packages with no authors
index_of_no_authors = which(unlist(lapply(CRAN_cranly_data$author, length)) == 0)

# replacing with maintainers
for(i in 1:length(which(unlist(lapply(CRAN_cranly_data$author, length)) == 0))){
  #i = 1
  CRAN_cranly_data$author[[index_of_no_authors[i]]] = CRAN_cranly_data$maintainer[index_of_no_authors[i]]
}



# Building author and package networks
# All_data = board %>% pin_read("All_data")
aut_network <- build_network(CRAN_cranly_data, perspective = 'author')
pac_network <- build_network(CRAN_cranly_data, perspective = 'package')
All_data = list("aut_network" = aut_network, "pac_network" = pac_network)
# board %>% pin_write(All_data, "All_data", type = "rds")


# All_data_igraph = as.igraph(All_data$pac_network)
pac_network_igraph = as.igraph(All_data$pac_network)

# Just looking at Packages with assigned task view
# Packages that are assigned to a Task View and are not hosted on CRAN 
not_in_CRAN = Reduce(c,tvdb_pkgs(tvdb_vec()))[!(Reduce(c,tvdb_pkgs(tvdb_vec())) %in% CRAN_data$Package)]
packages_assigned_Task_View = Reduce(c,tvdb_pkgs(tvdb_vec()))
# Removing the packages that are not hosted on CRAN
packages_assigned_Task_View = packages_assigned_Task_View[!(packages_assigned_Task_View %in% not_in_CRAN)]
# Removing duplicates
packages_assigned_Task_View = unique(packages_assigned_Task_View)



# Just looking at Hard Depenedencies
# dep_imp_edges = which(!is.element(E(All_taskviews_igraph)$type, c("depends","imports", "linking_to"))) 
# All_taskviews_rem_edges_igraph = delete.edges(All_taskviews_igraph, dep_imp_edges)



########################################################################################## 

# taskviews_of_pckgs     = board %>% pin_read("taskviews_of_pckgs")
# Creating list of packages with the task views assigned to each one
# This code is a modified version of the generating_taskviews script

taskviews_of_pckgs = vector(mode = "list", length = length(packages_assigned_Task_View))

for(j in 1:length(packages_assigned_Task_View)){
  for(i in 1:length(tvdb)){
    print(paste(j,i))
    if(packages_assigned_Task_View[j] %in% tvdb_pkgs(tvdb_vec()[i])) {
      
      taskviews_of_pckgs[[j]] = append(taskviews_of_pckgs[[j]], tvdb_vec()[i])
      
    }
  }
}


names(taskviews_of_pckgs) = packages_assigned_Task_View

#taskviews_of_pckgs$trackeR
# board %>% pin_write(taskviews_of_pckgs, "taskviews_of_pckgs", type = "rds")




##########################################################################################



########## Creating the response matrix #######

response_matrix = matrix(0, nrow = length(all_CRAN_pks), ncol = length(tvdb_vec()) + 1)
colnames(response_matrix) = c(tvdb_vec(), "none")

# Creating matrix that denotes which Task View(s) each package belongs to
for(i in 1:length(all_CRAN_pks)){
  #i = 6214
  #i = 13672
  
  if(is.null(taskviews_of_pckgs[[all_CRAN_pks[i]]])){
    
    response_matrix[i,"none"] = 1
    
  } else {
    
    
    response_matrix[i,taskviews_of_pckgs[[all_CRAN_pks[i]]]] = 1
    
  }
}

rownames(response_matrix) = all_CRAN_pks

#response_matrix["trackeR",]



##########################################################################################



########## Creating features/predictors ######

##### Creating  Proportion of neighboring packages feature matrix ####
# creating graph object removing soft dependencies

# Giving a Task View attribute to the pac_network
pac_network_igraph = set_vertex_attr(pac_network_igraph, name = "taskview",
                                  index = packages_assigned_Task_View,
                                  taskviews_of_pckgs[packages_assigned_Task_View])

# check:
# V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "ggplot2"]
# V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "trackeR"]


# Deleting the soft dependencies between packages
soft_dependencies_edges = which(!is.element(E(pac_network_igraph)$type, c("depends","imports", "linking_to"))) 
taskviews_pac_network_rem_edges_igraph = delete.edges(pac_network_igraph, soft_dependencies_edges)




# feature_matrix_all_neighbour_pkgs     = board %>% pin_read("feature_matrix_all_neighbour_pkgs")
# Creating matrix where for each package it gives the proportion of immediate hard dependencies.
# In the `neighbours` function `mode` is set to `c("all")` meaning that we are looking at on both
# dependencies of a package and its reverse dependencies.
feature_matrix_all_neighbour_pkgs = matrix(0, nrow = length(all_CRAN_pks), ncol = length(tvdb_vec()) + 1)
colnames(feature_matrix_all_neighbour_pkgs) = c(tvdb_vec(), "none")

for(i in 1:length(all_CRAN_pks)){
  
  print(i)
  neigh = neighbors(taskviews_pac_network_rem_edges_igraph, all_CRAN_pks[i], mode = c("all"))$taskview
  n_none = sum(unlist(lapply(neigh, function(x){is.null(x)})))
  props = (prop.table(table(c(unlist(neigh), rep("none", n_none)))))
  
  feature_matrix_all_neighbour_pkgs[i,names(props)] = as.vector(props)
  
}

rownames(feature_matrix_all_neighbour_pkgs) = all_CRAN_pks

# board %>% pin_write(feature_matrix_all_neighbour_pkgs, "feature_matrix_all_neighbour_pkgs", type = "rds")









##### Load Features using text data of packages #####
# This has been created in the NLP R script. Reliant on the number of package available on GitHub page.
# feature_matrix_titles_descriptions_packages_cosine     = board %>% pin_read("feature_matrix_titles_descriptions_packages_cosine")
#source(file = "NLP.R")
#load(file = "Data/feature_matrix_titles_descriptions_packages_cosine.RData")








##### Proportion of other packages that Author worked on  ####
# feature_matrix_author_task_views = board %>% pin_read("feature_matrix_author_task_views")

# calculated by taking the authors of the package, getting the packages that they worked on.
# Then looking at the proportion of the assignment to Task Views of these packages

authors_of_packages = All_data$pac_network$nodes$author
names(authors_of_packages) = All_data$pac_network$nodes$package
authors_of_packages = authors_of_packages[all_CRAN_pks]


packages_of_authors = All_data$aut_network$nodes$package
names(packages_of_authors) = All_data$aut_network$nodes$author 


fun1 = function(x){
  
  # when given a vector of Authors, returns a vector of the proportion of the Task Views of the packages qorked on by the authors 
  z = unlist(taskviews_of_pckgs[unique(unlist(packages_of_authors[x]))])
  
  if(is.null(z)){
    author_tsk_view_prop = c(rep(0,length(tvdb_vec())),1)
    names(author_tsk_view_prop) = c(tvdb_vec(), "none")
    
    
  }else{
    author_tsk_view_prop = prop.table(table(z))
    mat_fill = matrix(0, nrow = 1, ncol = length(tvdb_vec()) + 1)
    colnames(mat_fill) = c(tvdb_vec(), "none")
    mat_fill[1,names(author_tsk_view_prop)] = as.vector(author_tsk_view_prop)
    author_tsk_view_prop = mat_fill
  }
  
  return(author_tsk_view_prop)
  
  }

library(pbapply)
feature_matrix_author_task_views = pblapply(authors_of_packages, fun1)

feature_matrix_author_task_views = do.call(rbind, feature_matrix_author_task_views)
row.names(feature_matrix_author_task_views) = names(authors_of_packages)

colnames(feature_matrix_author_task_views) = paste0(colnames(feature_matrix_author_task_views), ".Author_props")
#save(feature_matrix_author_task_views, file = paste0("Code/Multinomial_models/Predictors/",date,"/feature_matrix_author_task_views.RData"))

# board %>% pin_write(feature_matrix_author_task_views, "feature_matrix_author_task_views", type = "rds")




###### 






#### load from pre-saved ####
#load(file = paste0("Code/Multinomial_models/Predictors/",date,"/feature_matrix_author_task_views.RData"))

##########################################################################################











########## Creating training and testing data sets ##########################################################################################
# I am going to split the labeled data with 80:20 ratio
# The labeled data consists of:
#             > Packages with assigned Task Views
#             > Packages with no Task View that meet assigned download Threshold




# merging feature matrices
feature_matrix_all_neighbour_pkgs_df = as.data.frame(feature_matrix_all_neighbour_pkgs)
feature_matrix_author_task_views_df = as.data.frame(feature_matrix_author_task_views)

feature_matrix_titles_descriptions_packages_cosine_df = as.data.frame(feature_matrix_titles_descriptions_packages_cosine)
feature_matrix_titles_descriptions_packages_cosine_df = t(feature_matrix_titles_descriptions_packages_cosine_df)


# Making sure all feature matrices and response matrix have correct rownames in correct order
# Response matrix
response_matrix
# Package Dependencies 
feature_matrix_all_neighbour_pkgs
# Text data
feature_matrix_titles_descriptions_packages_cosine_df
# Author collaborators
feature_matrix_author_task_views

# Create a final vector of package names that have rows for all the feature matrices and response matrix
# So what I have done is used rows that have data for all of the feature matrices and the response matrix
final_package_names =
                Reduce(intersect,list(row.names(response_matrix),
                                row.names(feature_matrix_all_neighbour_pkgs),
                                row.names(feature_matrix_titles_descriptions_packages_cosine_df),
                                row.names(feature_matrix_author_task_views)))

final_package_names = unique(final_package_names)

response_matrix                                       = response_matrix[final_package_names,]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[final_package_names,]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[final_package_names,]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[final_package_names,]


# Double checking duplicates
response_matrix                                       = response_matrix[!duplicated(row.names(response_matrix)),]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[!duplicated(row.names(feature_matrix_all_neighbour_pkgs)),]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[!duplicated(row.names(feature_matrix_titles_descriptions_packages_cosine_df)),]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[!duplicated(row.names(feature_matrix_author_task_views)),]

features = merge(feature_matrix_titles_descriptions_packages_cosine_df, feature_matrix_all_neighbour_pkgs_df, by="row.names", all.x = TRUE, )
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]
colnames(features) = gsub(colnames(features), pattern = "\\.x", replacement = ".text")
colnames(features) = gsub(colnames(features), pattern = "\\.y", replacement = ".neigh_packs")


features = merge(features, feature_matrix_author_task_views_df, by="row.names", all.x = TRUE)
# features = as.numeric(as.matrix(features))
nrow(features)
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]




# board %>% pin_write(features, "features", type = "rds")
# board %>% pin_write(response_matrix, "response_matrix", type = "rds")
# board %>% pin_write(final_package_names, "final_package_names", type = "rds")
# 
